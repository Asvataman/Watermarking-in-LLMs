# Watermarking Large Language Models

A proof-of-concept implementation of the watermarking technique described in ["A Watermark for Large Language Models"](https://arxiv.org/abs/2301.10226) by Kirchenbauer et al.

## Project Overview

This project implements a system for imperceptibly watermarking text generated by Large Language Models (LLMs) and subsequently detecting this watermark with high accuracy. The implementation focuses on a practical deployment using Azure OpenAI services.

## Demo

[Link to YouTube video demonstration]

## Features

- **LLM Watermarking**: Add statistical watermarks to text generated by GPT-4o
- **Watermark Detection**: Analyze text to determine if it contains a watermark
- **Interactive Chat Interface**: Toggle watermarking on and off in a chat environment
- **Visualization Tools**: Visual representation of watermark detection results
- **Azure OpenAI Integration**: Production-ready deployment with Azure services

## Watermarking Technique

The watermarking technique works by:

1. Using a deterministic hash function to generate a "green list" of tokens for each position in the text
2. Applying a logit bias to promote the selection of green list tokens during generation
3. Statistically analyzing the proportion of green tokens to detect the watermark

## Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/llm-watermarking.git
cd llm-watermarking

# Create and activate a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Configuration

Create a `.env` file in the project root with your Azure OpenAI API credentials:

```
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_ENDPOINT=your_endpoint_here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2025-03-01-preview

# Watermarking parameters
WATERMARK_GAMMA=0.5
WATERMARK_DELTA=2.0
DETECTION_THRESHOLD=4.0
WATERMARK_SEED=42
```

## Usage

### Running the Application

```bash
streamlit run app.py
```

This will start the Streamlit application, which includes:
- A chat interface with toggle for watermarking
- A detection tool for analyzing text for watermarks

### Programmatic Usage

**Watermarking Generation**:

```python
from watermarking import Watermarker
from utils import get_azure_client

# Initialize watermarker and client
watermarker = Watermarker(gamma=0.5, delta=2.0, seed=42)
client = get_azure_client()

# Generate text with watermark
response = watermarker.generate_with_watermark(
    client=client,
    messages=[{"role": "user", "content": "Tell me about watermarking."}],
    temperature=0.7,
    max_tokens=1000
)

watermarked_text = response.choices[0].message.content
print(watermarked_text)
```

**Watermark Detection**:

```python
from watermarking import WatermarkDetector

# Initialize detector
detector = WatermarkDetector(gamma=0.5, seed=42, threshold=4.0)

# Detect watermark in text
text_to_analyze = "Your text here..."
results = detector.detect(text_to_analyze)

# Print results
print(f"Is watermarked: {results['is_watermarked']}")
print(f"Z-score: {results['z_score']}")
print(f"P-value: {results['p_value']}")
```

## Project Structure

```
.
├── app.py                  # Main Streamlit application
├── config/                 # Configuration settings
├── ui/                     # Streamlit UI components
│   ├── chat_interface.py   # Chat interface implementation  
│   ├── detection_panel.py  # Watermark detection panel
│   └── sidebar.py          # Settings sidebar
├── utils/                  # Utility functions
│   ├── azure_client.py     # Azure OpenAI client
│   ├── text_processing.py  # Text preprocessing
│   └── token_utils.py      # Tokenization utilities
├── watermarking/           # Watermarking implementation
│   ├── watermarker.py      # Watermarking algorithm
│   └── detector.py         # Detection algorithm
├── trail                   # Implementation using open source model
└── requirements.txt        # Project dependencies
```

## Findings and Limitations

Our implementation with Azure OpenAI services revealed several key insights:

1. **Limited Effectiveness of Logit Bias**: In Azure's implementation of GPT-4o, logit bias values between -5 and 10 showed minimal impact on token selection, making watermarking less effective than expected.

2. **Quality Degradation**: Bias values exceeding 12 caused severe degradation in response quality, resulting in repetitive, incoherent text.

3. **API Limitations**: Azure OpenAI API restricts logit bias to 300 entries, requiring selective application of the watermark.

These findings highlight the gap between academic implementations (with direct access to model internals) and commercial API implementations.

## Future Work

- Implement adaptive watermarking based on text entropy
- Explore private watermarking with cryptographic techniques
- Improve robustness against editing and paraphrasing
- Investigate alternative bias application methods for Azure OpenAI

## Contributors

- Asvataman (AXV230014) - Watermarking implementation and Azure integration
- Sriman Sathish (SXS240032) - Detection algorithm and UI development

## Citations

This project implements the technique described in:

Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., & Goldstein, T. (2023). A Watermark for Large Language Models. *arXiv:2301.10226*. [https://arxiv.org/abs/2301.10226](https://arxiv.org/abs/2301.10226)

## License

[MIT License](LICENSE)