# Watermarking Large Language Models

## Background
Large Language Models (LLMs) have become increasingly powerful and prevalent in generating human-like text. However, this capability raises concerns about the potential misuse of AI-generated content, including misinformation, academic dishonesty, and copyright infringement. There is a growing need for reliable methods to distinguish between human-written and AI-generated text.

## Objective
This project aims to implement and evaluate a proof-of-concept (POC) for the watermarking technique described in the paper *A Watermark for Large Language Models* by Kirchenbauer et al., 2023. The goal is to create a system that can imperceptibly watermark text generated by an LLM and subsequently detect this watermark with high accuracy.

## Scope
1. **Implement the watermarking algorithm**:
   - Develop a pseudo-random token selection mechanism.
   - Modify the LLM's output distribution to incorporate the watermark.
   - Generate watermarked text using the modified model.

2. **Implement the watermark detection algorithm**:
   - Recreate the pseudo-random token lists for a given piece of text.
   - Perform statistical analysis to determine the presence of a watermark.

3. **Evaluate the effectiveness of the watermarking technique**:
   - Measure detection accuracy on watermarked and non-watermarked texts.
   - Assess the impact of watermarking on text quality and coherence.
   - Analyze the robustness of the watermark against various attack scenarios.

4. **Explore potential improvements and variations of the technique**:
   - Experiment with different watermarking parameters.
   - Investigate scalability across different model sizes and architectures.

## Deliverables
The project will produce:
1. A functional implementation of both the watermarking and detection algorithms.
2. A comprehensive evaluation report detailing performance metrics, limitations, and findings.
3. A set of sample watermarked texts along with corresponding detection results.
4. Documentation outlining the implementation process, challenges encountered, and solutions developed.

## Significance
This project contributes to ongoing efforts to ensure responsible development and use of AI language models. A successful implementation of this watermarking technique could provide a valuable tool for content attribution and help mitigate risks associated with widespread use of powerful language models.

## Workload Division
To ensure efficient collaboration, tasks are divided as follows:

- **Sriman Sathish (SXS240032)**:
  - Implement the core watermarking algorithm with pseudo-random token selection and logit modification.
  - Develop a text generation pipeline integrating watermarking across various LLMs.

- **Asvataman (AXV230014)**:
  - Implement the statistical watermark detection algorithm and evaluation metrics.
  - Create a text classification system to distinguish between watermarked and non-watermarked content.


